# python入门
# Pytorch入门
## Lesson1.张量(Tensor)的创建和常用方法
```python
import pytorch

# 查看版本号
torch.__version__
'1.7.1'
```

### 一、张量(Tensor)的基本创建及其类型
和NumPy中的dnarray-一样，张量的本质也是结构化的组织了大量的数据。并且，

在实际操作过程中，张量的创建和基本功能也和NumPy中的array非常类似。

#### 1.张量(Tensor)函数创建方法
张量的最基本创建方法和NumPy中创建Array的格式一致，都是创建函数（序列）

的格式：张量创建函数：torch.tensor()

```python
# 通过列表创建张量
t = torch.tensor([1,2])
t
```

tensor([1,2])

```python
# 通过元组创建张量
torch.tensor((1,2))
```

tensor([1,2])

```python
import numpy as np
a = np.array((1,2))
a
```

array((1,2))

```python
# 通过数组创建张量
t1 = torch.tensor(a)
t1
```

tensor([1,2],dtype=torch.int32)

这里可以看出，张量是具有类型的



**2.张量的类型**

dtype方法，可返回张量类型

```python
a.dtype   # np创建的函数array
```

dtype('int32')

```python
t.dtype   # 列表创建的张量
```

torch.int64

```python
t1.dtype  # 经过tensor改过的np array
```

torch.int32

<font style="background-color:#FBDE28;">在这里，我们发现，整数型的数组默认创建int32(整型)</font>

<font style="background-color:#FBDE28;">类型，而张量则默认创建int64(长整型)类型。</font>

```python
np.array([1.1,2.2]).dtype
```

dtype('float64')

```python
torch.tensor(np.array([1.1,2.2])).dtype
```

torch.float64

```python
torch.tensor([1.11,2.2]).dtype
```

torch.float32

相对的，创建浮点型数组时，<font style="color:#DF2A3F;background-color:#FBDE28;">张量默认是float32(单精度浮点型)，而Array则是默认float64(双精度浮点型)</font>

当然，除了数值型张量，常用的常量类型还有<font style="color:#DF2A3F;">布尔型张量</font>，也就是构成张量的各元素都是布尔类型的张量。

```python
t2 = torch.tensor([True,False])
t2
```

tensor([True,False])

```python
t2.dtype
```

torch.<font style="color:#DF2A3F;">bool</font>

总结：

<!-- 这是一张图片，ocr 内容为：PYTORCH中TENSOR类型 数据类型 DTYPE 32BIT浮点数 TORCH.FLOAT32或TORCH.FLOAT 64BIT浮点数 TORCH.FLOAT64或TORCH.DOUBLE TORCH.FLOAT16或TORCH.HALF 16BIT浮点数 8BIT无符号整数 TORCH.UNIT8 8BIT有符号整数 TORCH.INT8 16BIT有符号整数 TORCH.INT16或TORCH.SHORT 16BIT有符号整数 TORCH.INT16或TORCH.SHORT 32BIT有符号整数 TORCH.INT32或TORCH.INT 64BIT有符号整数 TORCH.INT64或TORCH.LONG 布尔型 TORCH.BOOL 复数型 TORCH.COMPLEX64 -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1748506356882-ccc81404-e14a-4fa4-a3e7-b47817dd8cdc.png)

除了默认的类型，也可以在创建张量过程中设置输出结果。

```python
# 创建int16整型张量
torch.tensor([1.1,2.7],dtype = torch.int16)
```

tensor([1,2],dtype=torch.int16)

当然，在pytorch中也支持复数类型对象创建

```python
a = torch.tensor(1 + 2j)   # 1是实部，2是虚部
a
```

tensor(1. + 2.j)



**3.张量类型的转化**

+ 张量类型的隐形转化

和Numpy中array相同，当张量各元素属于不同类型时，系统会自动进行隐形转化

```python
# 浮点型和整数型的隐形转化  =》变成数值浮点型
torch.tensor([1.1,2])
```

tensor([1.1000,2.0000])

```python
torch.tensor([1.1,2]).dtype
```

torch.float32



```python
# 布尔型和数值型的隐式转化  =》变成数值浮点型
torch.tensor([True,2.0])
```

tensor([1.,2.])   

```python
torch.tensor([True,2.0]).dtype
```



+ 张量类型的转化方法

<!-- 这是一张图片，ocr 内容为：当然,我们还可以使用,FLOATO,INT(等方法对张量类型进行转化. [61]: [61]: TENSOR([1, 2]) #转化为默认浮点型(32位) [62]: T.FLOAT() [62]: TENSOR([1., 2.]) 转化为双精度浮点型 [63]: T.DOUBLE() [63]: TENSOR([1.,2.],DTYPE-TORCH.FLOAT64) [65]: T.DTYPE TORCH.INT64 65] -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1748508159226-8baee933-52ec-4ed5-8ad3-ba5b393ee310.png)

### 二.张量的维度和形变
张量作为一组数的结构化表示，也同样拥有维度的概念。简答理解，向量就是一维的数组，而矩阵则是二维的数组，以此类推，在张量中，我们还可以定义更高维度的数组。当然，张量的高维数组和NumPy中高维Array概念类似。

1.创建高维向量

+ 用简单序列创建一维数组

包含“简单“元素的序列可创建一维数组。

```python
t1 = torch.tensor([1,2])
t1
```

tensor([1,2])

```python
# 使用ndim属性查看张量的维度
t1.ndim
```

1

```python
# 使用shape查看形状
t1.shape   # 包含两个元素的张量
```

torch.Size([2])

```python
t1.size()
```

torch.Size([2])

> <font style="color:#DF2A3F;background-color:#FBDE28;">pytorch中size和shape方法返回结果一样，Numpy中不是</font>
>

**其他查看张量形状方法**:

```python
# 返回拥有几个（N-1）维元素
len(t1)
```

2

```python
# 返回拥有几个（N-1）维元素
len(1，2，3)
```

3

```python
# 返回总共有几个数
t1.numel()
```

2

+ 创建二维数组

```python
# 用list的list创建二维数组
t2 = torch.tensor([[1,2],[3,4]])
t2
```

tensor([[1,2],[3,4]])

```python
t2.ndim
```

2       二维张量

```python
t2.shape
```

torch.Size([2,2])

```python
t2.size()
```

torch.Size([2,2])

```python
len(t2)
```

2    表示t2由两个一维张量构成

```python
t2.numel()
```

4

理解：此处numel方法返回结果代表t2总共由4个数构成





+ **"零"维张量**

只包含一个元素，但又不是单独的一个数

```python
t0 = torch.tensor([1])
t0
```

tensor([1])

```python
t = torch.tensor(1)
t
```

tensor(1)

```python
t0.ndim
```

1

```python
t.ndim
```

0

```python
t.shape
```

torch.Size([])

```python
t.numel()
```

1

理解零维张量：

目前，我们可将零维张量视为拥有张量属性的单独一个数。（例如，<font style="background-color:#FBDE28;">张量可以存在GPU上，但Python原生的数值型对象不行，但零维张量可以，尽管是零维</font>。)从学术名称来说，Python中单独一个数是scalars(标量)，而零维的张量则是tensor。





+ **高维张量**



```shell
a1 = np.array([[1,2,2],[3,4,4]])
a1
```

array([[1,2,2],[3,4,4]])

```shell
a2 = np.array([[5,6,6],[7,8,8]])
a2
```

array([[1,2,3],[3,4,4]])

```shell
# 有两个形状相同的数组创建一个三维的张量
t3 = torch.tensor([a1,a2])
t3
```

<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749379153323-f00b659a-0f6d-4199-b56f-317721e8ad97.png)

```shell
t3.ndim  # 三维
```

3

```shell
t3.shape  # 包含两个，两行三列的矩阵的张量
```

torch.Size([2,2,3])

```shell
len(t3)  # 两个元素（矩阵）组成
```

2

```shell
t3.numel()  # 总共有12个元素
```

12  



#### 2.张量的形变
张量作为数字的结构化集合，其结构也是可以根据实际需求灵活调整的。

##### 2.1flatten拉平：将任意维度张量转化为一维张量
```shell
t2
```

<!-- 这是一张图片，ocr 内容为：TENSOR([1, 2], [3,4]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749434573135-d2e0f22c-0009-4bcd-b81c-ff6cfd98d26d.png)

```shell
t2.flatten()
```

<!-- 这是一张图片，ocr 内容为：TENSOR([1, 2, 3, 4]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749434599500-451ee873-4c69-4ff1-8e4f-291540e4a099.png)

按行排列，拉平。

```shell
t3
```

<!-- 这是一张图片，ocr 内容为：TENSOR([[1, 2, 2], [3, 4, 4]], [[5, 6, 6], [7,8,8]]]], DTYPE-TORCH.INT32) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749434689298-4dadc390-ce4b-49e1-9f56-c1118a0027e2.png)

```shell
t3.flatten()
```

<!-- 这是一张图片，ocr 内容为：TENSOR([1, 2, 2, 3, 4, 4, 5, 6, 6, 7, 8], DTYPE-TORCH.INT32) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749434718368-2a6de022-04fe-4620-ad51-b1ecd9081411.png)

注：如果将零维张量使用flatten，则会将其转化为一维张量。

```shell
t
```

<!-- 这是一张图片，ocr 内容为：TENSOR(1) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749434779224-b05670e6-6618-4f38-a2dd-7e580ff45e3b.png)

```shell
t.flatten()
```

<!-- 这是一张图片，ocr 内容为：TENSOR([1]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749434841729-e69c90c9-10a9-4908-a5e0-aaa7b2d0a4c6.png)

```shell
t.flatten().ndim   # 一维张量
```

1

##### 2.2reshape方法：任意变形
```shell
t1
```

tensor([1,2])

```shell
# 转化为两行，一列的向量
t1.reshape(2,1)
```

<!-- 这是一张图片，ocr 内容为：TENSOR([1], [2]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749435442592-8be31951-3351-459c-a0d4-7451032c5530.png)

注意，reshape过程中维度的变化：reshape转化后的维度由该方法输入的参数"个数"决定.

+ **转化后生成一维张量**

```shell
t1.reshape(2)
```

<!-- 这是一张图片，ocr 内容为：TENSOR([1, 2]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749435635360-e38cbd59-0997-4f59-9f72-08539696123e.png)

```shell
# 另一种表达方式，和上面一样
t1.reshape(2,)   
```

+ **转化后生成二维张量**

```shell
t1
```

<!-- 这是一张图片，ocr 内容为：TENSOR([1, 2]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749436230404-960faac8-bb8a-41d6-b131-daddeb53800c.png)

```shell
t1.reshape(1,2)    # 生成包含一个两个元素的二维张量
```

<!-- 这是一张图片，ocr 内容为：TENSOR([[1, 2]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749436182966-0c4bc385-ca3b-4dc3-8c9f-378a671e1a60.png)   <font style="color:#DF2A3F;background-color:#FBDE28;">这里和上面有区别</font>

```shell
t1.reshape(1,2).ndim
```

<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749436328944-5bf6d161-b079-4f06-9a6e-13a64a09a51f.png)

+ **转化后生成三维张量**

```shell
t1.reshape(1,1,2)
```

<!-- 这是一张图片，ocr 内容为：TENSOR([[1, 2]]]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749436445339-f325ac4f-692f-4059-ab70-82bd89fb8e78.png)

```shell
t1.reshape(1,2,1)
```

<!-- 这是一张图片，ocr 内容为：TENSOR([[[1], [2]]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749436473948-c7df3928-9334-46f0-b622-9e3127da2798.png)

```shell
# 注意转化过程维度的变化
t1.reshape(1,2,1).ndim
```

<!-- 这是一张图片，ocr 内容为： -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749436526237-9553bb96-2e5e-4e80-a40e-e311d79fae87.png)

### 三.特殊张量的创建方法
在很多数值科学计算的过程中，都会创建一些特殊取值的张量，用于模拟特殊取值的矩阵，如<font style="color:#DF2A3F;">全0矩阵</font>、<font style="color:#DF2A3F;">对角矩阵</font>等。因此，PyTorch中也存在很多创建特殊张量的函数。

#### 1.特殊取值的张量创建方法
+ 全0张量

```shell
torch.zeros([2,3])   # 创建全是0的，两行，三列的张量（矩阵）
```

<!-- 这是一张图片，ocr 内容为：TENSOR([[0.,0., 0.], [0.,0.,0.]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749517523506-8489044d-364e-459b-b189-2b65f730f022.png)

> 注：由于zeros就已经确定了张量元素取值，因此该函数传入的参数实际上是决定了张量的形状。
>

+ 全1张量

```shell
torch.ones([2,3])
```

<!-- 这是一张图片，ocr 内容为：TENSOR([[1.,1.,1.], [1.,1., 1.]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749517962638-f53cdcb7-5162-435e-a5be-fe6906698728.png)

张量和列表，数组之间的转化

+ 单位矩阵

```shell
torch.eye(5)
```

<!-- 这是一张图片，ocr 内容为：TENSOR([1.,0.,0.,0.,0.], [0.,1.,0.,0.],0.], [0.,0.,1.,0.], [0.,0.,0.,1.,0.], [0.,0.,0.,0.,1.]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749518819438-90c0f86a-cded-4aa5-81ef-89d31ff6938f.png)

+ 对角矩阵

略有特殊的是，在pytorch中，需要利用一维张量去创建对角矩阵

```shell
t1
```

<!-- 这是一张图片，ocr 内容为：TENSOR([1, 2]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749518901356-a14d3cd3-5a8a-4924-81ed-03ca03964a56.png)

```shell
torch.diag(t1)
```

<!-- 这是一张图片，ocr 内容为：TENSOR([1,0], [O, 2]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749520976941-3c535fb0-4204-40b0-aa01-68f7d389567c.png)

```shell
torch.diag([1,2])   # 不能使用list直接创建对角矩阵
```

<!-- 这是一张图片，ocr 内容为：TRACEBACK (MOST RECENT CALL LAST) TYPEERROR <IPYTHON-INPUT-237-314C189CB631> IN <MODULE> --->>1 TORCH.DIAG([1,2]) 不能使用LIST互级创建对鱼矩阵 MUST BE TENSOR,NOT LIST TYPEERROR:DIAG():ARGUMENT"INPUT'(POSITION -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749521090520-2bb97103-6077-4694-bf3e-d649cd91342f.png)

+ rand: 服从0-1均匀分布的张量

```shell
torch.rand(2,3)
```

<!-- 这是一张图片，ocr 内容为：TENSOR([0.9223,0.9948,0.2804] [0.8130,0.2890,0.5319]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749521118547-bffc9eff-76f3-4297-ba5a-24dcbed34989.png)

+ randn: 服从标准正态分布的张量

```shell
torch.randn(2,3)
```

<!-- 这是一张图片，ocr 内容为：TENSOR( OR([-1.2513, 0.6465,-2.3011], [0.8447, 1.6856, 1.3615]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749522834936-cb517f9a-3ed4-4512-8052-02417bf05c4e.png)

+ normal: 服从指定正态分布的张量

```shell
torch.nomal(2,3,size = (2,2))    # 均值为2，标准差为3的张量
```

补充知识：

<!-- 这是一张图片，ocr 内容为：知识梳理 概率全攻略 数学大叔 下面这三点是帮助你理解正态密度曲线的, F(.0)- 要仔细体会哦~~ /2元O ID(SNX @这个函数的解析式是:QW(X)二 204, XE(-00,TOO) Y2TO 0 服从正态分布记作X~N(U,O2),读作"X服从正态分布" 这里的指的就是期望,也就是这组数据的平均数; 这里的6指的就是标准差,标准差就是方程开根号, 那么02就是方差咯,所以它描述的是这组数据的分散程度. 数学大叔 -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749693991814-602bf114-0412-487e-ad17-c99e1f62f7a3.png)

<!-- 这是一张图片，ocr 内容为：知识梳理 数学大叔 概率全攻略 正态分布的性质 (X) V2TO (1)曲线在X轴上方,与X轴不相交; (2)曲线是单峰的,它关于直线X-U对称; (3)曲线在XJ处达到峰值 B /2元0 W (4)曲线与X围成的面积是1;(记住就好啦) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749694173406-867b5a5d-7cfb-4500-9b52-122a39e06dd7.png)<!-- 这是一张图片，ocr 内容为：正态分布的性质 :位置 M 0--0 10-1 6-0.5 -0.5 0.15 O-2 112 143 (5)当.一定时,曲线的位置 (6)由于曲线与X轴围城的面积是 由U确定,随着" 固定的,那么当U一定时,曲线的 轴平移; 形状由O确定,.越小(越集中) 曲 曲线就高瘦,.越大(越分散) 线越矮胖, -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749694385504-adbaf955-73c2-4569-8e0e-88f1596bb86b.png)<!-- 这是一张图片，ocr 内容为：30原则是什么鬼? 68.26% 95.44% 99.74% 7291 P(4-0<X4+0)>0.6826, P4-20<X44,9544,P544,P(U-30<X￥U+30)>0)>0.9974) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749694475020-baf79f8f-219a-44a4-8f93-a7ae93f50193.png)

+ 整数随机采样结果

```shell
torch.randint(1,10,[2,4])   # 在1-10之间随机抽取整数，组成两行四列张量
```

<!-- 这是一张图片，ocr 内容为：TENSOR([5,8,8,8,3], [6,1,4, 2]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749695004286-5199129f-d268-4645-90d8-2f171d7a64cf.png)

+ arange/linspace: 生成数列

```shell
torch.arange(5)
```

<!-- 这是一张图片，ocr 内容为：TENSOR([0,1, 2, 3,4]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749695111056-2988b36c-0f99-4694-a9fe-4246cc096f02.png)



```shell
torch.arange(1,5,0.5)    # 从1到5（左闭右开） ，每隔0.5取值
```

<!-- 这是一张图片，ocr 内容为：TENSOR([1.000, 1.5000, 2.000,2.5000, 3.000, 3.5000, 4.000, 4.000, 4.5000] -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749695199100-4fd508a8-f993-4505-8f0d-aeca80af1003.png)

```shell
torch.linspace(1,5,3)     # 从1到5（左右都包含），等距取三个数
```

<!-- 这是一张图片，ocr 内容为：TENSOR([1., 3., 5.]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749695272338-5bb7a3db-7c86-492e-acd1-c01030b2a46b.png)

+ empty:生成未初始化的指定形状矩阵   ???

```shell
torch.empty(2,3)
```

<!-- 这是一张图片，ocr 内容为：TENSOR([[0.000E+00, 1.7740E+28, 1.8754E+28], [1.0396E-05, 1.0742E-05, 1.0187E-11]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749695613815-ddb139da-da86-431c-9ba9-e70b71d3fbe1.png)

+ <font style="color:#DF2A3F;">full:根据指定形状，填充指定数值</font>

```shell
torch.full([2,4],2)
```

<!-- 这是一张图片，ocr 内容为：TENSOR([2, 2, 2, 2], [2, 2, 2, 2]] -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749695715084-f0c76c58-0af2-4abc-b72e-d3fdf36fb386.png)

#### 2.创建指定形状的数组
当然，我们还能根据指定对象的形状进行数值填充，只需要在上述函数后面加上_like即可。

<!-- 这是一张图片，ocr 内容为：[281]: T1 [281]: TENSOR([1, 2]) [267] T2 [267]: TENSOR([1, 2], [3,4]]) TORCH.FULL_LIKE(C1, 2) [269] 根据1形状,填充数值2 TENSOR([2, 2]) [269 TORCH.RANDINT_LIKE(T2,1,10) [275] [275]: TENSOR([4, 8], [5,8]]) [284]: TORCH.ZEROS LIKE(T1) [284]:TENSOR([0,0]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749695869360-53231bc2-1c0c-46af-a8c5-1d7991b8bc7b.png)

更多like函数，可查阅帮助文档；

需要注意一点的是，_like类型转化需要注意转化前后数据类型一致的问题；

```shell
torch.randn_like(t1)   # t1是整数，正态转化后变为浮点数，此时代码将报错
```

<!-- 这是一张图片，ocr 内容为：TRACEBACK (MOST RECENT CALL LAST) RUNTIMEERROR <IPYTHON-INPUT-285-82E06104E8A8> IN <MODULE> 1 TORCH.RANDN_LIKE(T1) RUNTIMEERROR:"NORMAL KERNEL_CPU"NOT IMPLEMENTED FOR ' LONG -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749797597234-02ac8d4d-2b80-44b6-97b7-418e804aa2fa.png)

先创建一个浮点型张量，再正态转化即可。

<!-- 这是一张图片，ocr 内容为：重新生成一个新的浮点型张量 TORCH.TENSOR([1.1, 2.2]) T10 T10 TENSOR([1.1000, 2.2000]) TORCH.RANDN LIKE(T10)I #即可执行相应的填充转化 TENSOR([1.0909,0.0379]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749797916011-be7ddcd4-5f00-4395-a671-e99b8752f1d4.png)

### 四.张量(Tensor)和其他相关类型之间的转化
张量、数组和列表是较为相似的三种类型对象，在实际操作过程中，经常会涉及三种对象的相互转化。在此前张量的创建过程中，我们看到torch.tensor函数可以直接将数组或者列表转化为张量，而我们也可以将张量转化为数组或者列表。另外，前文介绍了0维张量的概念，此处也将进一步给出零维张量和数值对象的转化方法。

+ numpy方法：张量转化为数组

```shell
t1
```

<!-- 这是一张图片，ocr 内容为：TENSOR([1, 2, 3, 4, 4, 5, 6, 7, 8, 9, 10]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749798061388-0bf9c5b6-c06f-42f3-8099-97576971d048.png)

```shell
t1.numpy()
```

<!-- 这是一张图片，ocr 内容为：9,10],DTYPEINT64) 7, ARRAY([ 1, -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749798079852-804e6263-03ea-4a35-9aff-4b2f96afe824.png)

```shell
# 当然，也可以通过np.array函数直接转化为array
np.array(t1)
```

<!-- 这是一张图片，ocr 内容为：5, 6, 9,10],DTYPEINT64) 4, 8, ARRAY([1, -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749798177217-8cd4810a-cf16-426d-a8d0-2dc66656fcba.png)

+ tolist方法：张量转化为列表

```shell
t1.tolist()
```

<!-- 这是一张图片，ocr 内容为：[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749798230217-e5f3eb23-cebb-4c7f-ab24-35aa78747fdf.png)

+ item()方法：转化为数值

在很多情况下我们需要将最终计算结果张量转化为单独的数值进行输出，此时要用item方法来执行。

<!-- 这是一张图片，ocr 内容为：TORCH.TENSOR(1) TENSOR(1) N.ITEM 1 -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749798986867-85112f11-0d1d-4f0c-8521-9437f441f5b0.png)

### 五.张量的深拷贝
Python中其他对象类型一样，等号赋值操作实际上是浅拷贝，<font style="color:#DF2A3F;">需要进行深拷贝，则需要使用clone方法</font>。

<!-- 这是一张图片，ocr 内容为：TORCH.ARANGE(10) T1 T1  TENSOR([0, 1,2, 3, 4, 5, 6, 7, 8, 9]) T11是T1的浅拷贝 T1 T11 T11  TENSOR([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749799193944-5e2c1b38-7610-4e3c-a98b-3f5ad7b78bae.png)<!-- 这是一张图片，ocr 内容为：T1[1] TENSOR(1) #T1修改 TI[1] 10 T1 10, , 2, 3, 4, 5, 6, 7, 8, 9]) TENSOR([0, -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1749799216614-71e3c994-b9bf-4e02-8f1a-56cd52d83123.png)

此时t11也会同步修改

<!-- 这是一张图片，ocr 内容为：#T11会同步修改 T11 TENSOR([1, 10, 3, 4, 4, 5, 6, 7, 8, 9, 10]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750036508597-2941421d-a0b9-4ef0-93de-16cedfe54030.png)

此处t1和t11二者指向相同的对象。而要使得t11不随t1对象改变而改变，则需要对t11进行深拷贝，从而使得t11单独拥有一份对象。

<!-- 这是一张图片，ocr 内容为：[55]: T1.CLONE T11 [56]: T1 3,  4, 5, 6,  7, 8, 8, 9]) 2, [56]:TENSOR([100, 10, [57]: T11 3, 4, 5, 5, 6, 7, 8, 9]) 2, [57]: TENSOR([100, 10, [58]: T1[0] [58]: TENSOR(100) [59]: TI[O] 200 T1 , 3, 4, 5, 6, 7, 8, 9]) [59]: TENSOR([200, 10, [60]: T11 3, 5, 7, 8, 9]) [60]: TENSOR([100, 10, -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750036831832-a241ca56-74c3-409a-b489-fed236df313a.png)

## Lesson2.张量的索引、分片、合并以及维度调整
```shell
import torch
import numpy as np
```

### 一、张量的符号索引
张量也是有序序列，我们可以根据每个元素在系统内的顺序"编号”，来找出特定的元素，也就是索引。

#### 1、一维张量的索引
一维张量的索引过程和Python原生对象类型的索引一致，基本格式遵循[start:end:step],索引的基本要点回顾如下。

<!-- 这是一张图片，ocr 内容为：TORCH.ARANGE(1,11) T1 T1 TENSOR([1, 2, 3, 3, 4, 5, 6, 7, 8, 9, 10]) [3]: 从左到右,从零开始 [4]: T1[O] TENSOR(1) [4] -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750039152367-d3dfe6e6-5f71-46e1-9518-910da7642d02.png)

> 注：张量索引出来的结果还是零维张量，而不是单独的数。要转化成单独的数，需要使用item()方法。
>

+ 冒号分隔，表示对某个区域进行索引，也就是所谓的切片

<!-- 这是一张图片，ocr 内容为：#索引其中2-9号元素,并且左包含右不包含 T1[1:8] TENSOR([2, 3, 4, 5, 6, 7,8]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750123838730-12e1ce71-88a0-4d38-ae04-d6aacf148aef.png)

+ 第二个冒号，表示索引的间隔

<!-- 这是一张图片，ocr 内容为：#索引其中2-9号元素,左包含右不包含,且隔两个数取 T1[1:8:2] TENSOR([2, 4, 6,8]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750123866331-0b060fd9-0614-43b5-a96d-8f9ac3411737.png)

+ 冒号前后没有值，表示索引这个区域

<!-- 这是一张图片，ocr 内容为：#从第二个元素开始索引,一直到结尾,并且每隔两个数取一个 T1[1:2] TENSOR([ 2, 6,8,10]) 4, -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750123996202-92d269d4-fd5a-4e82-a031-6a31d9370a64.png)

<!-- 这是一张图片，ocr 内容为：个元素开始索引到第9个元素(不包含),并且每隔两个数取 从第 T1[:8:2] TENSOR([1,3,5, 7]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750124038025-3f0a2348-d3af-45e0-85c6-7a13bb118286.png)

> 在张量的索引中，step位必须大于0
>

<!-- 这是一张图片，ocr 内容为：T1[9:1:1] (MOST RECENT CALL LAST) TRACEBACK VALUEERROR <IPYTHON-INPUT-312-B82BB967C8E2> IN <MODULE> ----1 T1[9:1:-1] VALUEERROR:STEP MUST BE GREATER THAN ZERO -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750124099501-fd2603b1-08a4-4e0d-95e3-b0eebe40756f.png)

#### 2、二维张量的索引
二维张量的索引逻辑和一维张量的索引逻辑基本相同，二维张量可以视为两个一维张量组合而成，而在实际的索引过程中，需要用逗号进行分隔，分别表示对哪个一维张量进行索引、以及具体的一维张量的索引。

<!-- 这是一张图片，ocr 内容为：TORCH.ARANGE(1,10).RESHAPE(3,3) T2 T2 TENSOR([1,2,2,3], [4,5,6], [7,8,9]]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750124543570-96525b8a-146c-4e6f-859d-b6aa55ee1127.png)

<!-- 这是一张图片，ocr 内容为：表示索引第一行,第二个(第二列的)元素 T2[O, 1] TENSOR(2) 表示索引第一行,每隔两个元素取 T2[0,:2] TENSOR([1,3]) 索引结果同上 T2[O,[O, 2]] TENSOR([1, 3]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750124602885-2a326771-ae41-49e2-88a8-bc1bf09f25b5.png)<!-- 这是一张图片，ocr 内容为：表示每隔两行取一行,并且每一行中每隔两个元素取一个 T2[::2,:2] TENSOR([1, 3], [7, 9]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750124918801-e8c1fce0-aff1-44d4-9608-6dd76573747c.png)<!-- 这是一张图片，ocr 内容为：索引第一行,第二行,第二列的元素 T2[[O,2],1] TENSOR([2,8]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750124980488-5d9baf9d-fe60-43a1-873a-c42730c216aa.png)

理解：对二维张量来说，基本可以视为是对矩阵的索引，并且行、列的索引遵照相同的索引规范，并用逗号进行分隔。

#### 3、三维张量的索引
在二维张量索引的基础上，三维张量拥有三个索引的维度。我们将三维张量视作矩阵组成的序列，则在实际索引过程中拥有三个维度，分别是索引矩阵、索引矩阵的行、索引矩阵的列。

<!-- 这是一张图片，ocr 内容为：TORCH.ARANGE(1,28).RESHAPE(3,3,3) T3 T3 工 1, 2, TENSOR([[[ 3], ] [[10,11,12], [13,14,15], [16, 17, 18]], [[19,20,21], [22, 23,24], [25, 26, 27]]]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750125319750-caa67c57-db64-47d7-bbc7-c7bf1ced974a.png)<!-- 这是一张图片，ocr 内容为：#索引第二个矩阵中,第二行,第二个元素 T3[1, 1, 1] TENSOR(14) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750125397824-3267eb39-0bcb-4a09-b0fc-420dc6c48231.png)<!-- 这是一张图片，ocr 内容为：T3[1,:2,:2] #索引第二个矩阵,行和列都是每隔两个取一个 TENSOR([[10, 12], [16, 18]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750125478771-cba3d7a3-616f-4615-b155-64ea6f105358.png)<!-- 这是一张图片，ocr 内容为：T3[::2,:: 每隔两个取一个矩阵,对于每个矩阵来说,行和列都是每隔两 TENSOR([[[[ [ 7, -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750125637009-e7d55eb7-35e7-49f4-8275-54c9ad25e5ee.png)

理解：更为本质的角度去理解高维张量的索引，其实就是围绕张量的"形状“进行索引<!-- 这是一张图片，ocr 内容为：T3.SHAPE TORCH.SIZE([3,3,3]) 对应 T3[1,1,1] SSHAPE TENSOR(14) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750125674468-7daf0a68-965b-48df-bb17-c818447ecc12.png)

### 二、张量的函数索引
在PyTorch中，我们还可以使用index_selecti函数，通过指定index来对张量进行索引。

<!-- 这是一张图片，ocr 内容为：T1 4, 5, 5,6,7,8,8,9,10]) 2, TENSOR([1, T1.NDIM INDICES TORCH.TENSOR([1, 2]) INDICES TENSOR([1, 2]) TORCH.INDEX SELECT(T1,0,INDICES) TENSOR([2,3]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750125804872-1c61e81d-fc4e-4497-9e4c-0453ae779043.png)

<!-- 这是一张图片，ocr 内容为：TORCH.ARANGE( 12).RESHAPE(4, 3) T2 T2 2], TENSOR([[ 47 5], 11 9G 8] (9,10,11J1) T2.SHAPE TORCH.SIZE([4,3]) INDICES TENSOR([1, 2]) TORCH.INDEX_SELECT(T2,0,INDICES) TENSOR([3,4, 5], [6, 7,8]]) DIM参数取值为0,代表在SHAPE的第一个维度上索引 -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1752134857147-549de640-51db-41a1-aea7-ac16d0869e95.png)<!-- 这是一张图片，ocr 内容为：TORCH.INDEX_SELECT(T2,1,INDICES) TENSOR([1 1, [7,8], [10, 11]]) DIM参数取值为1,代表在SHAPE的第一个维度上索引 -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1752134898482-32b36adc-5c90-4afb-83c3-0a1999329baf.png)

### 三、tensor.view()方法
在正式介绍张量的切分方法之前，需要首先介绍PyTorch中的.view0方法。该方法会返回一个类似视图的结果，该结果和原张量对像共享一块数据存储空间，并且通过.view()方法，还可以改变对象结构，生成一个不同结构，但共享一个存储空间的张量。当然，<font style="color:#DF2A3F;">共享一个存储空间，也就代表二者是“浅拷贝“的关系，修改其中一个，另一个也会同步进行更改</font>。

<!-- 这是一张图片，ocr 内容为：[25] TORCH.ARANGE(6).RESHAPE(2,3) [25]: TENSOR([0, 1, 2], [3,4, 5]]) 构建一个数据相同,但形状不同的"视图" [26] T.VIEW(3,2) TE TE [26]: TENSOR([0, 1], [2, 3], [4, 5]]) [27]:  T [27]: TENSOR([0, 1, 2], [3, 4, 5]]) 对T进行修改 T[O] -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1752135252106-6641de6a-aef9-4fcd-a3ee-b22e3f74733c.png)

此时t和te都发生了变化

<!-- 这是一张图片，ocr 内容为：[34]: [34]: TENSOR([[1, 1, 1], [3, 4, 5]]) [72]: #TE同步变化 TE [72]: TENSOR([[1, 1], [1,3], [4, 5]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1752135517067-e0cdebd9-ebe9-48a1-9b47-023926d23d09.png)

### 四、张量的分片函数
**1.chunk函数**

chunk函数能的够按照某维度，对张量进行均匀切分，并且返回结果是原张量的视图。

<!-- 这是一张图片，ocr 内容为：[90]: TORCH.ARANGE(12).RESHAPE(4,3) T2 T2 [90]:TENSOR([[ 5], L 8], 6,7 9, 10, 11]] 在第零个维度上(按行),进行四等分 TORCH.CHUNK(T2,4,DIM-0) [91]: TC TC [91]:(TENSOR([[0, 1, 2]]), TENSOR([3,4, 5]]), TENSOR([6,7,8]]]]), TENSOR([[9,10,111111)) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1752136174638-9c8980d8-a8b1-4e1f-b97c-d2779545b11d.png)

注意：chunki返回结果是一个视图，不是新生成了一个对像

**2.****<font style="background-color:#FBDE28;">split函数</font>**

split<font style="color:#DF2A3F;">既能进行均分，也能进行自定义切分</font>。当然，需要注意的是，和chunk函数一样，spliti返回结果也是view。

<!-- 这是一张图片，ocr 内容为：[44]: TENSOR([[ 8 ,10,11]]) 均分情况 #第二个参数只输入一个数值时表示均分,第三个参数表 TORCH.SPLIT(T2,2,0) [109]: [109]: (TENSOR([[0, 1, 2], [3,4, 5]]]), TENSOR([6,7,7, 8], [ 9, 10, 11]])) #第二个参数输入一个序列时,表示按照序列数值. [121]: TORCH.SPLIT(T2,[1,3],0] [121]: (TENSOR([[0, 1, 2]]), TENSOR([3, 4, 5], [6,7,8], [9, 10, 11]])) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1752137067808-4d051efa-211a-4777-bbe2-f0207133f8af.png)

注意，当第二个参数位输入一个序列时，序列的各数值的和必须等于对应维度下形状分量的取值。例如，上述代码中，是按照第一个维度进行切分，而t2总共有4行，因此序列的求和必须等于4，也就是1+3=4，而序列中每个分量的取值，则代表切块大小。

<!-- 这是一张图片，ocr 内容为：TORCH.SPLIT(T2,[1,2],1) TS TS (TENSOR([[0], [3], [6] TENSOR([[1, 2], [4, 5], [ 7, 8], 11] 10 -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1752217710959-26927c6a-1432-409c-8597-90154a81c585.png)

### 五、张量的合并操作
张量的合并操作类似与列表的追加元素，可以拼接、也可以堆叠。

+ **拼接函数：cat**

Pytorch中，可以使用cat函数实现张量的拼接。

<!-- 这是一张图片，ocr 内容为：[147]: TORCH.ZEROS(2, 3) [147]: TENSOR([0.,0.,0.], [0.,0.,0.]]) [148]: TORCH.ONES(2,3) B B [148]: TENSOR([[1., 1., 1.], [1., 1., 1.]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1752217947036-719f92a7-6dc8-4c3c-8fa6-2f9de78e306b.png)<!-- 这是一张图片，ocr 内容为：[149]:C TORCH.ZEROS(3,3) C [149]: TENSOR([0.,0.,0.], [0.,0.,0.], [0.,0.,0.]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1752217962578-69eec986-6923-49dd-81b0-436f1a3eb307.png)

按行合并a和b

<!-- 这是一张图片，ocr 内容为：按照行进行拼接,DIM默认取值为 [150] TORCH.CAT([A, B]) # [150]:TENSOR([[0K,0.,0.], [0.,0.,0.], [1.,1.,1.], [1., 1., 1.]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1752218279947-68934d19-d086-4376-8833-b7732d2a1d8f.png)

按列合并a和b<!-- 这是一张图片，ocr 内容为：按照列进行拼接 [151]: TORCH.CAT([A, B], [151]: TENSOR([0.,0.,0.,0.,1.,1.],1.], [0.,0., 0., 1.,1., 1.]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1752218345903-54a07280-6e3d-47b4-80f8-43f29709768c.png)

形状不匹配，会报错

<!-- 这是一张图片，ocr 内容为：形状不匹配时将报错 TORCH.CAT([A, C],1) TRACEBACK (MOST RECENT CALL LAST) RUNTIMEERROR <IPYTHON-ILPUT-59-8BDD1A857266>IN <MODULE> 形实在正时装拍摄 TORCH.CAT([A, C],1) RUNTIMEERROR: SIZES OF TENSORS MUST MATCH EXCEPT IN DIMENSION 1.GOT 2 AND 3 DIMENSION 0 (THE OFFENDING DING INDEX IS 1) IN -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1752218577562-7261aab0-92e0-4bcc-be89-30623a04bfda.png)

注意理解，拼接的本质是实现元素的堆积，也就是构成a、b两个二维张量的各一维张量的堆积，最终还是构成二维向量。

+ **堆叠函数：stack**

和拼接不同，堆叠不是将元素拆分重装，而是简单的将各参与堆叠的对象分装到一个更高维度的张量里。

<!-- 这是一张图片，ocr 内容为：[60]: [60]: TENSOR([[E.]0., 0.], [0.,0.,0.]]) [61]: B [61]: TENSOR([[1., 1., 1.], [1.,1., 1.]]) [62]: TORCH.STACK([A, B]) 堆叠之后,生成一个三维张量 [62]: TENSOR([[[0., 0.,0.], [0.,0.,0.]], [[1.,1.,1.], [1., 1., 1.]]]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1752218943093-6420ecc5-e71b-4afd-ba67-6cd0bed6a6eb.png)

堆叠后生成一个三维向量

<!-- 这是一张图片，ocr 内容为：堆叠之后,生成一个三维张量 TORCH.STACK([A, B]) [62]: [62]: TENSOR([[0.,0.,0.], [0.,0.,0.]], [157]: TORCH.STACK([A,B]).SHAPE [157]: TORCH.SIZE([2, 2, 3]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1752220836703-96969bc8-4b6e-4c96-8ffe-5f398fa3fa86.png)

### 六、张量的维度变换
此前我们介绍过，通过reshape方法，能够灵活调整张量的形状。而在实际操作张量进行计算时，往往需要另外进行降维和升维的操作，当我们需要除去不必要的维度时，可以使用squeezel函数，而需要手动升维时，则可采用unsqueeze函数。

<!-- 这是一张图片，ocr 内容为：[63]: TORCH.ARANGE(4) [63]: TENSOR([0, 1, 2, 3]) [65] A.RESHAPE(1,4) A2 A2 , 1, 2,3]]) [65]:TENSOR([[O, [68]:TORCH.SQUEEZE(A2).NDIM [68]: 1 -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1753858018376-d05396a1-c638-472f-bd72-dcd712bc12ea.png)

squeezel函数<!-- 这是一张图片，ocr 内容为：SQUEEZE函数:删除不必要的维度 [175]: TORCH.ZEROS(1,3,1) [175]:TENSOR([[[0.], [0.], [0.]]11]) [177]:T.SHAPE [177]: TORCH.SIZE([1, 1, 3, 1]) 张量解释:一个包含一个三维的四维张量,三维张量只包含一个三行一列的二维张 量. -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1753858072301-87b447ab-558e-4497-bbd6-b7f2da07bdfd.png)<!-- 这是一张图片，ocr 内容为：[176]:TORCH.SQUEEZE(T) [176]: TENSOR([O.,0.,0.]) [178]:TORCH.SQUEEZE(T).SHAPE [178]:TORCH.SIZE -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1753858160667-14050995-9da0-4a10-b3cd-488ba3a1e02c.png)

unsqueeze函数

<!-- 这是一张图片，ocr 内容为：UNSQEEZE函数:手动升维 [200]: T TORCH.ZEROS(1, 2,1, 2) T.SHAPE [200]: TORCH.SIZE([1, 2, 1, 2]) 在第1个维度索引上升高1个维度 [209]:TORCH.UNSQUEEZE(T,DIM 0) [209]: TENSOR([[[[0.,0.,0.]], [[0., 0.]]]]]) [210]: TORCH.UNSQUEEZE(T,DIM 0).SHAPE [210]: TORCH.SIZE([1, 1, 2, 1, 2]) 在第3个维度索引上升高1个维度 TORCH.UNSQUEEZE(T,DIM2)SHAPE [207]: [207]: TORCH.SIZE([1, 2, 1, 1, 2]) -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1753858278264-9a856ccb-27f8-4496-96b2-9971d1886e91.png)

## Lesson3.张量的广播和科学运算
### 1.张量的广播
+ 数学运算和算子

 	作为PyTorch中执行深度学习的基本数据类型，张量(Tensor)也拥有非常多的数学运算函数和方法，以及对应的一系列计算规则。在PyTorch中，能够作用与Tensor的运算，被统一称作为算子。并且相比于NumPy,PyTorch给出了更加规范的算子（运算）的分类，从而方便用户在不同场景下调用不同类型的算子（运算）。

+ 数学运算的分类

PyToch,总共为Tensori设计了六大类数学运算，分别是：

1.逐点运算(Pointwise Ops):指的是针对Tensor中每个元素执行的相同运算操作；

2规约运算(Reduction Ops)：指的是对于某一张量进行操作得出某种总结值：

3.比较运算(Comparison Ops):指的是对多个张量进行比较运算的相关方法：

4.谱运算(Spectral Ops):指的是涉及信号处理傅里叶变化的操作：

5<font style="color:#DF2A3F;background-color:#FBDE28;">.BLAS和LAPACK运算</font>：指的是基础线性代数程序集(Basic Linear Algeria Subprograms)和线性代数		包	(Linear Algeria Package)中定义的、主要用于线性代数科学计算的函数和方法：

6.其他运算(Other Ops):其他未被归类的数学运算。

由于谱运算(Spectral Ops)前期不会涉及，而要理解傅里叶变换本身需要更多额外的数学基础，而很多其他运算，我们在前面介绍张量的基本方法时已经介绍，因此接下来将主要围绕逐点运算、规约运算、比较运算和线性代数运算四块进行讲解，而线性代数部分由于涉及到大量的数学内容，因此将放在Lesson4中单独进行讲解。

### 2.逐点运算
### 3.规约运算
### 4.比较运算


# NLP基础入门


# Transformer原理
# 顶尖大模型原理与架构实现








<!-- 这是一张图片，ocr 内容为：交付物 序号 五院超算平台功能扩展升级建设方案 五院超算平台功能扩展升级测试报告 五院超算平台功能扩展升级安装部署说明 五院超算平台功能扩展升级用户手册 五院超算平台功能扩展升级研制总结 五院超算平台功能扩展升级源代码及安装包 6. -->
![](https://cdn.nlark.com/yuque/0/2025/png/21360294/1750294569579-d0a827f6-74ab-4d03-90f8-ad1b8a42ed6e.png)

+ 项目概述
    - 项目背景和目的
    - 项目范围和预期成果
+ 软件研制过程
    - 系统架构设计
        * 整体架构
        * 技术选型
        * 模块划分
+ 系统组成
+ 项目实施
+ 项目交付
+ 项目总结

